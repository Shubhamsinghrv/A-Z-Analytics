{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c728572b-3ecc-4a64-aa7b-75531be5d059",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 10:35:15,671 - INFO - Starting Flask application\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 10:35:15,679 - INFO - \u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://10.160.0.3:5000\n",
      "2025-03-10 10:35:15,680 - INFO - \u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "2025-03-10 10:35:25,005 - INFO - 47.247.157.210 - - [10/Mar/2025 10:35:25] \"\u001b[31m\u001b[1mGET /upload HTTP/1.1\u001b[0m\" 405 -\n",
      "2025-03-10 10:35:25,775 - INFO - 47.247.157.210 - - [10/Mar/2025 10:35:25] \"\u001b[31m\u001b[1mGET /upload HTTP/1.1\u001b[0m\" 405 -\n",
      "/var/tmp/ipykernel_24529/2567273051.py:68: DeprecationWarning: Assignment to 'Bucket.location' is deprecated, as it is only valid before the bucket is created. Instead, pass the location to `Bucket.create`.\n",
      "  bucket.location = location\n",
      "2025-03-10 10:35:39,886 - INFO - Bucket user-rohan-f1525898-95e7-4ebc-bb14-a10630830bb9 created in ASIA-SOUTH1\n",
      "2025-03-10 10:35:39,889 - INFO - File saved to temporary location: /var/tmp/tmpyi6jbf_3\n",
      "2025-03-10 10:35:40,188 - INFO - File /var/tmp/tmpyi6jbf_3 uploaded to user-rohan-f1525898-95e7-4ebc-bb14-a10630830bb9/House_Price_India.csv.\n",
      "2025-03-10 10:35:40,191 - INFO - 47.247.157.210 - - [10/Mar/2025 10:35:40] \"POST /upload HTTP/1.1\" 200 -\n",
      "2025-03-10 11:48:22,784 - INFO - 64.62.197.25 - - [10/Mar/2025 11:48:22] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n",
      "2025-03-10 11:48:32,510 - INFO - 64.62.197.30 - - [10/Mar/2025 11:48:32] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from werkzeug.utils import secure_filename\n",
    "import logging\n",
    "import re\n",
    "import traceback\n",
    "from flask_cors import CORS\n",
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "import tempfile\n",
    "import os\n",
    "import uuid\n",
    "import json\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "ALLOWED_EXTENSIONS = {'csv'}\n",
    "MAX_FILE_SIZE = 2 * 1024 * 1024 * 1024\n",
    "GCP_PROJECT_ID = 'decisive-sylph-449809-j4'\n",
    "USER_BUCKET_MAP_FILE = 'user_buckets.json'\n",
    "BUCKET_LOCATION = 'asia-south1'  # Mumbai region\n",
    "\n",
    "app.config['MAX_CONTENT_LENGTH'] = MAX_FILE_SIZE\n",
    "app.secret_key = 'prmis'\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"app.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def allowed_file(filename):\n",
    "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
    "\n",
    "def is_valid_csv(file_path):\n",
    "    try:\n",
    "        pd.read_csv(file_path, nrows=5)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Invalid CSV format: {e}\")\n",
    "        return False\n",
    "\n",
    "pattern = re.compile(r'(\\.exe|\\.bat|\\.sh|\\.cmd|\\.msi|\\.vbs|\\.js|\\.ps1)', re.IGNORECASE)\n",
    "\n",
    "def scan_for_executables_in_chunk(chunk):\n",
    "    for col in chunk.columns:\n",
    "        for value in chunk[col].dropna().astype(str):\n",
    "            cleaned_value = value.strip().replace('\"', '').replace(\"'\", \"\")\n",
    "            if pattern.search(cleaned_value):\n",
    "                logger.warning(f\"Executable reference detected in column '{col}': {value}\")\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def upload_to_gcs(bucket_name, file_path, destination_blob_name):\n",
    "    storage_client = storage.Client(project=GCP_PROJECT_ID)\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "    blob.upload_from_filename(file_path)\n",
    "    logger.info(f\"File {file_path} uploaded to {bucket_name}/{destination_blob_name}.\")\n",
    "\n",
    "def create_gcs_bucket(bucket_name, location=BUCKET_LOCATION):\n",
    "    storage_client = storage.Client(project=GCP_PROJECT_ID)\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    bucket.location = location\n",
    "    bucket = storage_client.create_bucket(bucket)\n",
    "    logger.info(f\"Bucket {bucket.name} created in {bucket.location}\")\n",
    "    return bucket.name\n",
    "\n",
    "def get_user_bucket_map():\n",
    "    try:\n",
    "        with open(USER_BUCKET_MAP_FILE, 'r') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return {}\n",
    "\n",
    "def save_user_bucket_map(user_buckets):\n",
    "    with open(USER_BUCKET_MAP_FILE, 'w') as f:\n",
    "        json.dump(user_buckets, f, indent=4)\n",
    "\n",
    "@app.route(\"/upload\", methods=[\"POST\"])\n",
    "def upload_file():\n",
    "    if \"files\" not in request.files:\n",
    "        logger.error(\"No files part in the request\")\n",
    "        return jsonify({\"error\": \"No files part in the request\"}), 400\n",
    "\n",
    "    files = request.files.getlist(\"files\")\n",
    "\n",
    "    username = request.form.get('username')\n",
    "    if not username:\n",
    "        logger.error(\"Username is required\")\n",
    "        return jsonify({\"error\": \"Username is required\"}), 400\n",
    "\n",
    "    user_buckets = get_user_bucket_map()\n",
    "\n",
    "    if username not in user_buckets:\n",
    "        # Create a new bucket if the user doesn't have one yet\n",
    "        bucket_name = f\"user-{username}-{uuid.uuid4()}\"\n",
    "        create_gcs_bucket(bucket_name)\n",
    "        user_buckets[username] = bucket_name\n",
    "        save_user_bucket_map(user_buckets)\n",
    "    else:\n",
    "        bucket_name = user_buckets[username]\n",
    "\n",
    "    uploaded_files = []\n",
    "    for file in files:\n",
    "        if file and allowed_file(file.filename):\n",
    "            try:\n",
    "                with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n",
    "                    file.save(temp_file.name)\n",
    "                    file_path = temp_file.name\n",
    "                    logger.info(f\"File saved to temporary location: {file_path}\")\n",
    "\n",
    "                    if not is_valid_csv(file_path):\n",
    "                        os.remove(file_path)\n",
    "                        return jsonify({\"error\": f\"File '{file.filename}' rejected: Invalid CSV format!\"}), 400\n",
    "\n",
    "                    chunk_size = 500000\n",
    "                    for chunk in pd.read_csv(file_path, chunksize=chunk_size, dtype=str):\n",
    "                        if scan_for_executables_in_chunk(chunk):\n",
    "                            os.remove(file_path)\n",
    "                            return jsonify({\"error\": f\"File '{file.filename}' rejected: Executable references detected!\"}), 400\n",
    "\n",
    "                    # Use the original filename for the destination\n",
    "                    destination_filename = secure_filename(file.filename)\n",
    "\n",
    "                    upload_to_gcs(bucket_name, file_path, destination_filename)\n",
    "                    os.remove(file_path)\n",
    "\n",
    "                    uploaded_files.append({\n",
    "                        \"filename\": destination_filename,\n",
    "                        \"bucket_name\": bucket_name\n",
    "                    })\n",
    "\n",
    "            except Exception as e:\n",
    "                trace = traceback.format_exc()\n",
    "                logger.error(f\"Error processing file {file.filename}: {e}\\n{trace}\")\n",
    "                return jsonify({\"error\": \"Internal server error\"}), 500\n",
    "        else:\n",
    "            return jsonify({\"error\": f\"Invalid file type uploaded: {file.filename}\"}), 400\n",
    "\n",
    "    return jsonify({\n",
    "        \"message\": \"Files uploaded successfully to GCP\",\n",
    "        \"uploaded_files\": uploaded_files\n",
    "    }), 200\n",
    "\n",
    "@app.route(\"/files\", methods=[\"GET\"])\n",
    "def list_files():\n",
    "    try:\n",
    "        storage_client = storage.Client(project=GCP_PROJECT_ID)\n",
    "        buckets = storage_client.list_buckets()\n",
    "        all_files = []\n",
    "        for bucket in buckets:\n",
    "            blobs = bucket.list_blobs()\n",
    "            files = [{\"bucket\": bucket.name, \"file\": blob.name} for blob in blobs if blob.name.endswith(\".csv\")]\n",
    "            all_files.extend(files)\n",
    "        logger.info(\"Listing uploaded files from GCS\")\n",
    "        return jsonify({\"files\": all_files, \"user_buckets\": get_user_bucket_map()}), 200\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error listing files from GCS: {e}\")\n",
    "        return jsonify({\"error\": \"Internal server error\"}), 500\n",
    "\n",
    "@app.route('/webhook', methods=['POST'])\n",
    "def webhook():\n",
    "    if request.method == 'POST':\n",
    "        return 'Webhook received!', 200\n",
    "    return 'Invalid request', 400\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger.info(\"Starting Flask application\")\n",
    "    app.run(host=\"0.0.0.0\", port=5000, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0866a33b-408f-4ef5-a6a4-16aed72e078b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce50fd30-b4c0-41f1-a21f-da9bdfd82714",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
